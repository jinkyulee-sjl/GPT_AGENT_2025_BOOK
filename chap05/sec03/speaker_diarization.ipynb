{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "005ae3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. 추가하려는 경로를 정의합니다.\n",
    "# Windows 경로를 다룰 때는 raw string(r\"...\")을 사용하는 것이 좋습니다.\n",
    "ffmpeg_path = r\"D:\\Study\\GPT_AGENT_2025_BOOK\\ffmpeg-7.1.1-full_build\\bin\"\n",
    "\n",
    "# 2. 현재 PATH 환경 변수를 가져옵니다.\n",
    "# os.pathsep은 운영체제에 맞는 경로 구분자(';' 또는 ':')를 자동으로 사용해줍니다.\n",
    "path_list = os.environ.get('PATH', '').split(os.pathsep)\n",
    "\n",
    "# 3. 추가하려는 경로가 이미 PATH에 있는지 확인합니다.\n",
    "if ffmpeg_path not in path_list:\n",
    "    # 4. PATH에 없는 경우에만 맨 앞에 추가합니다.\n",
    "    os.environ['PATH'] = ffmpeg_path + os.pathsep + os.environ.get('PATH', '')\n",
    "    print(f\"'{ffmpeg_path}' 경로를 PATH에 추가했습니다.\")\n",
    "else:\n",
    "    print(f\"'{ffmpeg_path}' 경로는 이미 PATH에 존재합니다.\")\n",
    "\n",
    "# (선택 사항) 변경된 PATH 확인\n",
    "print(\"\\n--- 현재 PATH ---\")\n",
    "print(os.environ['PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b557c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import winreg\n",
    "import ctypes\n",
    "\n",
    "# ==============================================================================\n",
    "# 중요: 1. 아래 FFMPEG_BIN_PATH에 본인의 FFmpeg bin 폴더 경로를 정확히 입력하세요.\n",
    "#         예: \"C:\\\\ffmpeg\\\\bin\" (백슬래시를 두 번 사용하거나 슬래시를 사용하세요)\n",
    "#       2. 이 셀을 실행하려면 Jupyter/VSCode를 \"관리자 권한으로 실행\"해야 할 수 있습니다.\n",
    "# ==============================================================================\n",
    "FFMPEG_BIN_PATH = r\"D:\\Study\\GPT_AGENT_2025_BOOK\\ffmpeg-7.1.1-full_build\\bin\" # <--- ‼️ 본인의 FFmpeg bin 폴더 경로로 수정하세요.\n",
    "\n",
    "def add_path_to_system_environment(path_to_add):\n",
    "    \"\"\"\n",
    "    Windows 시스템 환경 변수 PATH에 새로운 경로를 영구적으로 추가합니다.\n",
    "    관리자 권한이 필요하며, 변경 사항을 적용하려면 재시작이 필요합니다.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path_to_add):\n",
    "        print(f\"오류: '{path_to_add}'는 유효한 디렉터리가 아닙니다. 경로를 확인해주세요.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # 시스템 환경 변수에 접근하기 위해 레지스트리 키를 엽니다.\n",
    "        # HKEY_LOCAL_MACHINE은 시스템 전체에, HKEY_CURRENT_USER는 현재 사용자에게만 적용됩니다.\n",
    "        # 시스템 전체에 적용하려면 관리자 권한이 필요합니다.\n",
    "        key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, \n",
    "                             r'SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Environment', \n",
    "                             0, \n",
    "                             winreg.KEY_READ | winreg.KEY_WRITE)\n",
    "\n",
    "        # 현재 PATH 값을 읽어옵니다.\n",
    "        current_path_value, reg_type = winreg.QueryValueEx(key, 'Path')\n",
    "\n",
    "        # 경로들을 세미콜론(;)으로 분리합니다.\n",
    "        paths = current_path_value.split(';')\n",
    "\n",
    "        # 추가하려는 경로가 이미 포함되어 있는지 확인합니다.\n",
    "        if path_to_add in paths or path_to_add + '\\\\' in paths:\n",
    "            print(f\"'{path_to_add}' 경로는 이미 시스템 PATH에 존재합니다.\")\n",
    "        else:\n",
    "            # 새로운 경로를 추가합니다.\n",
    "            new_path_value = current_path_value + ';' + path_to_add\n",
    "            winreg.SetValueEx(key, 'Path', 0, reg_type, new_path_value)\n",
    "            print(f\"'{path_to_add}' 경로를 시스템 PATH에 성공적으로 추가했습니다.\")\n",
    "            \n",
    "            # 모든 프로그램에 변경 사항을 알립니다.\n",
    "            HWND_BROADCAST = 0xFFFF\n",
    "            WM_SETTINGCHANGE = 0x1A\n",
    "            ctypes.windll.user32.SendMessageW(HWND_BROADCAST, WM_SETTINGCHANGE, 0, \"Environment\")\n",
    "            print(\"모든 프로그램에 환경 변수 변경을 알렸습니다.\")\n",
    "\n",
    "        winreg.CloseKey(key)\n",
    "\n",
    "    except PermissionError:\n",
    "        print(\"\\n[오류] 권한이 거부되었습니다.\")\n",
    "        print(\"이 스크립트를 시스템 PATH에 쓰려면 관리자 권한이 필요합니다.\")\n",
    "        print(\"Jupyter Notebook 또는 VS Code를 '관리자 권한으로 실행'한 후 다시 시도해주세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"예상치 못한 오류가 발생했습니다: {e}\")\n",
    "\n",
    "# 함수 실행\n",
    "add_path_to_system_environment(FFMPEG_BIN_PATH)\n",
    "\n",
    "print(\"\\n======================================================================\")\n",
    "print(\"‼️ 중요: 변경 사항을 적용하려면 반드시 커널을 재시작하거나\")\n",
    "print(\"   VS Code/터미널을 완전히 종료 후 다시 실행해주세요!\")\n",
    "print(\"======================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b0aa72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: d:\\Study\\GPT_AGENT_2025_BOOK\\chap05\\sec03\n",
      "load_dotenv returned: True\n",
      "HF token found in environment (value not shown).\n",
      "Pipeline loaded successfully.\n",
      "CUDA available — pipeline moved to GPU.\n"
     ]
    }
   ],
   "source": [
    "# instantiate the pipeline with safer token handling and diagnostics\n",
    "from pyannote.audio import Pipeline\n",
    "from dotenv import load_dotenv\n",
    "import os, traceback\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "print(\"cwd:\", os.getcwd())\n",
    "# load .env (if present). load_dotenv returns True if a file was found\n",
    "ok = load_dotenv()\n",
    "print(\"load_dotenv returned:\", ok)\n",
    "\n",
    "# Prefer explicit token passing. Do NOT print the token value here for security.\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "if token:\n",
    "    print(\"HF token found in environment (value not shown).\")\n",
    "else:\n",
    "    print(\"No HF_TOKEN in environment. If the model is gated, you must set HF_TOKEN with a token that has Read permission.\")\n",
    "\n",
    "# Try to instantiate the pyannote pipeline. If it fails, capture and print guidance.\n",
    "try:\n",
    "    if token:\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", token=token)\n",
    "    else:\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\")\n",
    "    print(\"Pipeline loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load Pipeline.from_pretrained()\")\n",
    "    traceback.print_exc()\n",
    "    print(\"If the model is gated: create an HF token with Read permission and either set it as HF_TOKEN in your environment or pass it with token=token.\")\n",
    "    print(\"You can also accept the model terms on the Hugging Face model page if required.\")\n",
    "    raise\n",
    "\n",
    "# GPU: try to move pipeline to GPU but handle failures gracefully\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            pipeline.to(torch.device(\"cuda:0\"))\n",
    "            print(\"CUDA available — pipeline moved to GPU.\")\n",
    "        except Exception as e:\n",
    "            print(\"Could not move pipeline to GPU (possibly OOM). Continuing on CPU.\")\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"CUDA is not available — using CPU.\")\n",
    "except NameError:\n",
    "    # pipeline variable might not exist if instantiation failed\n",
    "    print(\"Pipeline not available to move to GPU. Skipping GPU move.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "workaround_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workaround function 'load_audio' defined. Use this to load audio files.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# [Workaround] torchcodec/torchaudio compatibility fix\n",
    "# ==============================================================================\n",
    "# Since torchcodec is incompatible with the current PyTorch version, we use\n",
    "# soundfile to load audio and pass the waveform directly to the pipeline.\n",
    "\n",
    "def load_audio(file_path):\n",
    "    \"\"\"\n",
    "    Load audio file using soundfile and convert to PyTorch tensor.\n",
    "    Returns a dictionary suitable for pyannote.audio pipeline.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {file_path}\")\n",
    "        \n",
    "    # Load audio using soundfile (returns numpy array)\n",
    "    # data shape: (time, channels) or (time,)\n",
    "    data, sr = sf.read(file_path)\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    waveform = torch.from_numpy(data).float()\n",
    "    \n",
    "    # Ensure shape is (channels, time)\n",
    "    if waveform.ndim == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "    else:\n",
    "        waveform = waveform.t()\n",
    "        \n",
    "    return {\"waveform\": waveform, \"sample_rate\": sr}\n",
    "\n",
    "print(\"Workaround function 'load_audio' defined. Use this to load audio files.\")\n",
    "\n",
    "# Example Usage:\n",
    "# audio_file = \"path/to/your/audio.wav\"\n",
    "# io = load_audio(audio_file)\n",
    "# diarization = pipeline(io)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f9188b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\GPT_AGENT_2025_BOOK\\venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:103: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1857.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DiarizeOutput' object has no attribute 'write_rttm'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m diarization = pipeline(io)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mD:/Study/GPT_AGENT_2025_BOOK/chap05/audio/싼기타_비싼기타.rttm\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m rttm:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mdiarization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite_rttm\u001b[49m(rttm)\n",
      "\u001b[31mAttributeError\u001b[39m: 'DiarizeOutput' object has no attribute 'write_rttm'"
     ]
    }
   ],
   "source": [
    "io = load_audio(\"D:/Study/GPT_AGENT_2025_BOOK/chap05/audio/싼기타_비싼기타.mp3\")\n",
    "diarization = pipeline(io)\n",
    "\n",
    "with open(\"D:/Study/GPT_AGENT_2025_BOOK/chap05/audio/싼기타_비싼기타.rttm\", \"w\", encoding=\"utf-8\") as rttm:\n",
    "    diarization.write_rttm(rttm)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
