{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005ae3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. 추가하려는 경로를 정의합니다.\n",
    "# Windows 경로를 다룰 때는 raw string(r\"...\")을 사용하는 것이 좋습니다.\n",
    "ffmpeg_path = r\"D:\\Study\\GPT_AGENT_2025_BOOK\\ffmpeg-7.1.1-full_build-shared\\bin\"\n",
    "\n",
    "# 2. 현재 PATH 환경 변수를 가져옵니다.\n",
    "# os.pathsep은 운영체제에 맞는 경로 구분자(';' 또는 ':')를 자동으로 사용해줍니다.\n",
    "path_list = os.environ.get('PATH', '').split(os.pathsep)\n",
    "\n",
    "# 3. 추가하려는 경로가 이미 PATH에 있는지 확인합니다.\n",
    "if ffmpeg_path not in path_list:\n",
    "    # 4. PATH에 없는 경우에만 맨 앞에 추가합니다.\n",
    "    os.environ['PATH'] = ffmpeg_path + os.pathsep + os.environ.get('PATH', '')\n",
    "    print(f\"'{ffmpeg_path}' 경로를 PATH에 추가했습니다.\")\n",
    "else:\n",
    "    print(f\"'{ffmpeg_path}' 경로는 이미 PATH에 존재합니다.\")\n",
    "\n",
    "# (선택 사항) 변경된 PATH 확인\n",
    "print(\"\\n--- 현재 PATH ---\")\n",
    "print(os.environ['PATH'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b557c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import winreg\n",
    "import ctypes\n",
    "\n",
    "# ==============================================================================\n",
    "# 중요: 1. 아래 FFMPEG_BIN_PATH에 본인의 FFmpeg bin 폴더 경로를 정확히 입력하세요.\n",
    "#         예: \"C:\\\\ffmpeg\\\\bin\" (백슬래시를 두 번 사용하거나 슬래시를 사용하세요)\n",
    "#       2. 이 셀을 실행하려면 Jupyter/VSCode를 \"관리자 권한으로 실행\"해야 할 수 있습니다.\n",
    "# ==============================================================================\n",
    "FFMPEG_BIN_PATH = r\"D:\\Study\\GPT_AGENT_2025_BOOK\\ffmpeg-7.1.1-full_build-shared\\bin\" # <--- ‼️ 본인의 FFmpeg bin 폴더 경로로 수정하세요.\n",
    "\n",
    "def add_path_to_system_environment(path_to_add):\n",
    "    \"\"\"\n",
    "    Windows 시스템 환경 변수 PATH에 새로운 경로를 영구적으로 추가합니다.\n",
    "    관리자 권한이 필요하며, 변경 사항을 적용하려면 재시작이 필요합니다.\n",
    "    \"\"\"\n",
    "    if not os.path.isdir(path_to_add):\n",
    "        print(f\"오류: '{path_to_add}'는 유효한 디렉터리가 아닙니다. 경로를 확인해주세요.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # 시스템 환경 변수에 접근하기 위해 레지스트리 키를 엽니다.\n",
    "        # HKEY_LOCAL_MACHINE은 시스템 전체에, HKEY_CURRENT_USER는 현재 사용자에게만 적용됩니다.\n",
    "        # 시스템 전체에 적용하려면 관리자 권한이 필요합니다.\n",
    "        key = winreg.OpenKey(winreg.HKEY_LOCAL_MACHINE, \n",
    "                             r'SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Environment', \n",
    "                             0, \n",
    "                             winreg.KEY_READ | winreg.KEY_WRITE)\n",
    "\n",
    "        # 현재 PATH 값을 읽어옵니다.\n",
    "        current_path_value, reg_type = winreg.QueryValueEx(key, 'Path')\n",
    "\n",
    "        # 경로들을 세미콜론(;)으로 분리합니다.\n",
    "        paths = current_path_value.split(';')\n",
    "\n",
    "        # 추가하려는 경로가 이미 포함되어 있는지 확인합니다.\n",
    "        if path_to_add in paths or path_to_add + '\\\\' in paths:\n",
    "            print(f\"'{path_to_add}' 경로는 이미 시스템 PATH에 존재합니다.\")\n",
    "        else:\n",
    "            # 새로운 경로를 추가합니다.\n",
    "            new_path_value = current_path_value + ';' + path_to_add\n",
    "            winreg.SetValueEx(key, 'Path', 0, reg_type, new_path_value)\n",
    "            print(f\"'{path_to_add}' 경로를 시스템 PATH에 성공적으로 추가했습니다.\")\n",
    "            \n",
    "            # 모든 프로그램에 변경 사항을 알립니다.\n",
    "            HWND_BROADCAST = 0xFFFF\n",
    "            WM_SETTINGCHANGE = 0x1A\n",
    "            ctypes.windll.user32.SendMessageW(HWND_BROADCAST, WM_SETTINGCHANGE, 0, \"Environment\")\n",
    "            print(\"모든 프로그램에 환경 변수 변경을 알렸습니다.\")\n",
    "\n",
    "        winreg.CloseKey(key)\n",
    "\n",
    "    except PermissionError:\n",
    "        print(\"\\n[오류] 권한이 거부되었습니다.\")\n",
    "        print(\"이 스크립트를 시스템 PATH에 쓰려면 관리자 권한이 필요합니다.\")\n",
    "        print(\"Jupyter Notebook 또는 VS Code를 '관리자 권한으로 실행'한 후 다시 시도해주세요.\")\n",
    "    except Exception as e:\n",
    "        print(f\"예상치 못한 오류가 발생했습니다: {e}\")\n",
    "\n",
    "# 함수 실행\n",
    "add_path_to_system_environment(FFMPEG_BIN_PATH)\n",
    "\n",
    "print(\"\\n======================================================================\")\n",
    "print(\"‼️ 중요: 변경 사항을 적용하려면 반드시 커널을 재시작하거나\")\n",
    "print(\"   VS Code/터미널을 완전히 종료 후 다시 실행해주세요!\")\n",
    "print(\"======================================================================\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0aa72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the pipeline with safer token handling and diagnostics\n",
    "from pyannote.audio import Pipeline\n",
    "from dotenv import load_dotenv\n",
    "import os, traceback\n",
    "import torch\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "print(\"cwd:\", os.getcwd())\n",
    "# load .env (if present). load_dotenv returns True if a file was found\n",
    "ok = load_dotenv()\n",
    "print(\"load_dotenv returned:\", ok)\n",
    "\n",
    "# Prefer explicit token passing. Do NOT print the token value here for security.\n",
    "token = os.getenv(\"HF_TOKEN\")\n",
    "if token:\n",
    "    print(\"HF token found in environment (value not shown).\")\n",
    "else:\n",
    "    print(\"No HF_TOKEN in environment. If the model is gated, you must set HF_TOKEN with a token that has Read permission.\")\n",
    "\n",
    "# Try to instantiate the pyannote pipeline. If it fails, capture and print guidance.\n",
    "try:\n",
    "    if token:\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\", use_auth_token=token)\n",
    "    else:\n",
    "        pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-3.1\")\n",
    "    print(\"Pipeline loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to load Pipeline.from_pretrained()\")\n",
    "    traceback.print_exc()\n",
    "    print(\"If the model is gated: create an HF token with Read permission and either set it as HF_TOKEN in your environment or pass it with token=token.\")\n",
    "    print(\"You can also accept the model terms on the Hugging Face model page if required.\")\n",
    "    raise\n",
    "\n",
    "# GPU: try to move pipeline to GPU but handle failures gracefully\n",
    "try:\n",
    "    if torch.cuda.is_available():\n",
    "        try:\n",
    "            pipeline.to(torch.device(\"cuda:0\"))\n",
    "            print(\"CUDA available — pipeline moved to GPU.\")\n",
    "        except Exception as e:\n",
    "            print(\"Could not move pipeline to GPU (possibly OOM). Continuing on CPU.\")\n",
    "            traceback.print_exc()\n",
    "    else:\n",
    "        print(\"CUDA is not available — using CPU.\")\n",
    "except NameError:\n",
    "    # pipeline variable might not exist if instantiation failed\n",
    "    print(\"Pipeline not available to move to GPU. Skipping GPU move.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "workaround_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# [Workaround] torchcodec/torchaudio compatibility fix\n",
    "# ==============================================================================\n",
    "# Since torchcodec is incompatible with the current PyTorch version, we use\n",
    "# soundfile to load audio and pass the waveform directly to the pipeline.\n",
    "\n",
    "def load_audio(file_path):\n",
    "    \"\"\"\n",
    "    Load audio file using soundfile and convert to PyTorch tensor.\n",
    "    Returns a dictionary suitable for pyannote.audio pipeline.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Audio file not found: {file_path}\")\n",
    "        \n",
    "    # Load audio using soundfile (returns numpy array)\n",
    "    # data shape: (time, channels) or (time,)\n",
    "    data, sr = sf.read(file_path)\n",
    "    \n",
    "    # Convert to PyTorch tensor\n",
    "    waveform = torch.from_numpy(data).float()\n",
    "    \n",
    "    # Ensure shape is (channels, time)\n",
    "    if waveform.ndim == 1:\n",
    "        waveform = waveform.unsqueeze(0)\n",
    "    else:\n",
    "        waveform = waveform.t()\n",
    "        \n",
    "    return {\"waveform\": waveform, \"sample_rate\": sr}\n",
    "\n",
    "print(\"Workaround function 'load_audio' defined. Use this to load audio files.\")\n",
    "\n",
    "# Example Usage:\n",
    "# audio_file = \"path/to/your/audio.wav\"\n",
    "# io = load_audio(audio_file)\n",
    "# diarization = pipeline(io)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9188b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# io = load_audio(\"../audio/싼기타_비싼기타.mp3\")\n",
    "# diarization = pipeline(io)\n",
    "diarization = pipeline(\"../audio/싼기타_비싼기타.mp3\")\n",
    "\n",
    "with open(\"../audio/싼기타_비싼기타.rttm\", \"w\", encoding=\"utf-8\") as rttm:\n",
    "    # diarization.speaker_diarization.write_rttm(rttm)\n",
    "    diarization.write_rttm(rttm)\n",
    "\n",
    "#print(diarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87276f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "rttm_path = \"../audio/싼기타_비싼기타.rttm\"\n",
    "df_rttm = pd.read_csv(\n",
    "    rttm_path,\n",
    "    sep =\" \",\n",
    "    header=None,\n",
    "    names=[\"type\", \"file\", \"chnl\", \"start\", \"duration\", \"C1\", \"C2\", \"speaker_id\", \"C3\", \"C4\"]\n",
    "    )\n",
    "print(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bc3e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start + duration을 end로 변환\n",
    "df_rttm['end'] = df_rttm['start'] + df_rttm['duration']\n",
    "display(df_rttm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cd3eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm['number'] = None\n",
    "df_rttm.at[0, 'number'] = 0\n",
    "\n",
    "display(df_rttm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f3acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(df_rttm)):\n",
    "    if df_rttm.at[i, 'speaker_id'] != df_rttm.at[i-1, 'speaker_id']:\n",
    "        df_rttm.at[i, 'number'] = df_rttm.at[i-1, 'number'] + 1\n",
    "    else:\n",
    "        df_rttm.at[i, 'number'] = df_rttm.at[i-1, 'number']\n",
    "\n",
    "display(df_rttm.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a1817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped = df_rttm.groupby(\"number\").agg(\n",
    "    start=pd.NamedAgg(column=\"start\", aggfunc=\"min\"),\n",
    "    end=pd.NamedAgg(column=\"end\", aggfunc=\"max\"),\n",
    "    speaker_id=pd.NamedAgg(column=\"speaker_id\", aggfunc=\"first\")\n",
    ")\n",
    "\n",
    "display(df_rttm_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d31f977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped[\"duration\"] = df_rttm_grouped[\"end\"] - df_rttm_grouped[\"start\"]\n",
    "df_rttm_grouped = df_rttm_grouped.reset_index(drop=True)\n",
    "display(df_rttm_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ff54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rttm_grouped.to_csv(\"../audio/싼기타_비싼기타.csv\",\n",
    "  sep=',', \n",
    "  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
